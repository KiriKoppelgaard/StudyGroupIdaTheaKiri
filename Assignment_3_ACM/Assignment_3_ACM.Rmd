---
title: "Assignment_3_ACM"
output: html_document
date: '2022-03-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#load packages
library(pacman)
p_load(tidyverse, here, posterior, cmdstanr, boot, brms)

#Load data
data <- read.csv("data/sc_schizophrenia.csv")

```


```{r}
#Adding variables
data <- data %>%
  mutate(Change = FirstRating - SecondRating) %>%
  mutate(Group = as.factor(ifelse(ID >=200, "C", "S"))) %>%
  mutate(Feedback = FirstRating - OtherRating)
data <- na.omit(data)

mean(data$Change[data$Group== "S"])
mean(data$Change[data$Group== "C"])


#PLOT EXPLORATION
ggplot(data, aes(x=Group, y=Feedback)) + geom_bar(stat = "summary", fun.y = "mean")

ggplot(data, aes(x=Feedback, y=Change,fill="red")) +
  geom_jitter(alpha=0.1) +
  facet_wrap(~ Group) + 
  geom_bar(stat = "summary", fun.y = "mean") +
  theme_bw()

#positive correlation. But individual differences:
ggplot(data, aes(x=Change, y= Feedback, col=Group)) +
  geom_point() +
  facet_wrap(~ID)

#individual differences in how the scale is used + restrictions (see notes):
ggplot(data, aes(x=FirstRating, y= Feedback, col=Group)) +
  geom_point() +
  facet_wrap(~ID)

```


```{r}
#Select data for single object 
data_s <- data[data$ID=="103",]

#Create data 
data_single <- list(
      N = max(data_s$Trial_Round2), 
      y = data_s$SecondRating/9,
      SourceSelf = data_s$FirstRating/9,
      SourceOther = data_s$OtherRating/9
    )


```


```{r}
#Import stan-file
file_simple <- file.path("W8_simpleBayes.stan")

#Compiling
mod_simple <- cmdstan_model(file_simple, cpp_options = list(stan_threads = TRUE), pedantic = TRUE)

```

```{r}
#Sampling
samples_simple <- mod_simple$sample(
    data = data_single,
    fixed_param = FALSE,
    seed = 123,
    chains = 2,
    parallel_chains = 2,
    threads_per_chain = 2,
    iter_warmup = 1000,
    iter_sampling = 1000,
    refresh = 1000,
    max_treedepth = 20,
    adapt_delta = 0.99)

samples_simple$summary()

```



```{r}
#Plotting model quality
ggplot(draws_df, aes(.iteration, theta, group=.chain, color=.chain)) +
geom_line()+
theme_classic()

samples_simple$cmdstan_diagnose()
```



---NOTES FROM CLASS

change ~ feedback
, so:
2rating ~ logit(1rating) + logit(otherrating)

^^ but this has issues!:

BUT BIAS/POTENTIAL CONFOUND: not all feedbacks are possible! (e.g. if rate 8, can only get negative (or 0) feedback)
- reg to the mean? -> how to discriminate btw going down from an 8 rating due to reg to mean, or due to conformity?


SECOND POINT:
prev model was Bernoulli, 0 or 1
But now we need to change the family/shape of the outcome
recommended for assignment:
- go with normal distribution (not unproblematic, since it's discrete data... but for now, fuck it).
- a function of mu (mean expected outcome) and sigma (not part of the model).
mu is logit(first rating) + logit(peerrating). deterministic in simple Bayes, just one value.
Stan doesn't like sigma of 0...
We should put sigma in as a parameter to be estimated! It's the avg error the model is making when predicting the data!
So the parameters (parameters to be estimated) AND model (form of the model) part of stan have to be filled. A model that actually estimates sigma.

we should not have fixed parameters = TRUE, since sigma isn't fixed






BIASES:
- ID plots also show: people differ in how much they use the rating scale





