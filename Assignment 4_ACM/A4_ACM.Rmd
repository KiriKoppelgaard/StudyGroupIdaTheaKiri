---
title: "A4_ACM"
output: html_document
date: '2022-04-22'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#libraries
library(pacman)
p_load(tidyverse, here, posterior, cmdstanr, boot, brms)

```

```{r}
file <- file.path('RW_2con.stan')

mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), pedantic = TRUE)
```

```{r}

trials_row <- c(50, 100, 200) #, 500, 1000, 2500, 5000, 7500, 9999)
d <- read.csv('data/10000trials_RL_data.csv')

for (trial_n in trials_row){
  print(trial_n)
  data <- list(
      trials = trial_n*2, 
      feedback = c(d$feedback[d$condition == 0.6][1:trial_n],d$feedback[d$condition == 0.8][1:trial_n]),
      choice = c(d$choice[d$condition == 0.6][1:trial_n],d$choice[d$condition == 0.8][1:trial_n]),
      con1 = c(d$con1[d$condition == 0.6][1:trial_n],d$con1[d$condition == 0.8][1:trial_n]),
      con2 = c(d$con2[d$condition == 0.6][1:trial_n],d$con2[d$condition == 0.8][1:trial_n])
      )
  
  samples <- mod$sample(
    data = data,
    seed = 123,
    chains = 2,
    parallel_chains = 2,
    threads_per_chain = 2,
    iter_warmup = 500,
    iter_sampling = 500,
    refresh = 500,
    max_treedepth = 15,
    adapt_delta = 0.99)
  
  draws_df <- as_draws_df(samples$draws())
  
  temp <- tibble(trials = trial_n, 
                 alpha1 = draws_df$alpha1,
                 alpha2 = draws_df$alpha2,
                 temperature = draws_df$temperature,
                 alpha_prior = draws_df$alpha_prior,
                 temperature_prior = draws_df$temperature_prior)
  
  if(exists("param_df")){param_df <- rbind (param_df, temp)} else {param_df <- temp}
}

```

#Plotting posteriors
```{r}
#Plotting prior and posterior for weights: Has the model learned from the data? 
ggplot(draws_df) +
  geom_density(aes(inv.logit(alpha1)), fill="blue", alpha=0.3) + 
  geom_density(aes(inv.logit(alpha_prior)), fill="red", alpha=0.3) +   xlab("Alpha1") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = 'Prior and posterior distribution for Alpha1')

#Plotting prior and posterior for weights: Has the model learned from the data? 
ggplot(draws_df) +
  geom_density(aes(inv.logit(alpha2)), fill="blue", alpha=0.3) + 
  geom_density(aes(inv.logit(alpha_prior)), fill="red", alpha=0.3) +   xlab("Alpha2") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = 'Prior and posterior distribution for Alpha2')


#Plotting prior and posterior for weights: Has the model learned from the data? 
ggplot(draws_df) +
  geom_density(aes(inv.logit(temperature)*20), fill="blue", alpha=0.3) + 
  geom_density(aes(inv.logit(temperature_prior)*20), fill="red", alpha=0.3) +   xlab("temperature") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = 'Prior and posterior distribution for temperature')

#Plotting prior and posterior for weights: Has the model learned from the data? 
ggplot(draws_df) +
  geom_density(aes(temperature), fill="blue", alpha=0.3) + 
  geom_density(aes(temperature_prior), fill="red", alpha=0.3) +   xlab("temperature") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = 'Prior and posterior distribution for temperature on log odds scale')

p1 + p2 + p3 + p4

```


[optional]: what happens if x is not = +.7 (tip: test a range of different x)?
[optional]: what happens if temperature is not 0.5, but 5?

# Part 2
Given the large number of trials required, could you imagine producing an iterated design? E.g. a phone app where you can do a smaller number of trials (e.g. 10-20 or even 100, up to you!) in separate sessions, each time a posterior is generated and it is used as prior in the next time.
Assuming no variance over time (ah!) can you figure out a good trade off between how many trials per session and number of sessions?






[optional]: what are the differences in just re-running the model on the cumulative dataset (increased at every session) vs passing the posterior? Differences in terms of computational time, estimates, but also practical implication for running your study.
[optional]: what happens if learning rate changes a bit across sessions? Include a variation between sessions according to a normal distribution with a mean of 0 and a sd of 0.02. Re-assess the number of trials/sessions used.


